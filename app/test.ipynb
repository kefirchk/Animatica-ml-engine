{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Real Time Animation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import libs and modules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "from src.services.animation import AnimationService\n",
    "from src.services.model import ModelService\n",
    "from src.services.video_animation import VideoAnimationService"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuration"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RELATIVE = True\n",
    "ADAPT_MOVEMENT_SCALE = True\n",
    "USE_CPU = True\n",
    "VIDEO_CODEC = 'MJPG'\n",
    "SOURCE_IMAGE_NAME = './data/input/nick.jpg'\n",
    "RESULT_VIDEO_DIR = './data/output'\n",
    "RESULT_VIDEO_NAME = './data/output/real_time_test.avi'\n",
    "MODEL_CONFIG_PATH = './data/configs/vox-256.yaml'\n",
    "MODEL_CHECKPOINT_PATH = './data/checkpoints/vox-cpk.pth.tar'\n",
    "WINDOW_NAME = 'Real Time Animation'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "os.makedirs('./data/output', exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare source image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "source_image = cv2.imread(SOURCE_IMAGE_NAME)\n",
    "source_image = cv2.cvtColor(source_image, cv2.COLOR_BGR2RGB)\n",
    "source_image = resize(source_image, (256, 256))[..., :3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.imshow(source_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_service = ModelService(\n",
    "    config_path=MODEL_CONFIG_PATH,\n",
    "    checkpoint_path=MODEL_CHECKPOINT_PATH,\n",
    "    cpu=USE_CPU,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "generator, kp_detector = model_service.load_eval_models()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_frame(frame, crop_box, target_size=(256, 256)):\n",
    "    x, y, w, h = crop_box\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = frame[y:y+h, x:x+w]\n",
    "    frame = resize(frame, target_size)[..., :3]\n",
    "    return frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def to_tensor(img, use_cpu=False):\n",
    "    tensor = torch.tensor(img[np.newaxis].astype(np.float32)).permute(0, 3, 1, 2)\n",
    "    return tensor if use_cpu else tensor.cuda()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_frame(source, kp_source, frame_tensor, kp_initial, generator, kp_detector):\n",
    "    kp_driving = kp_detector(frame_tensor)\n",
    "    kp_norm = AnimationService.normalize_kp(\n",
    "        kp_source=kp_source,\n",
    "        kp_driving=kp_driving,\n",
    "        kp_driving_initial=kp_initial,\n",
    "        use_relative_movement=RELATIVE,\n",
    "        use_relative_jacobian=RELATIVE,\n",
    "        adapt_movement_scale=ADAPT_MOVEMENT_SCALE,\n",
    "    )\n",
    "    out = generator(source, kp_source=kp_source, kp_driving=kp_norm)\n",
    "    prediction = out['prediction'][0].data.cpu().permute(1, 2, 0).numpy()\n",
    "    return prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare real time animation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "fourcc = cv2.VideoWriter_fourcc(*VIDEO_CODEC)\n",
    "out_video = cv2.VideoWriter(RESULT_VIDEO_NAME, fourcc, 12, (256 * 3, 256), True)\n",
    "\n",
    "source_rgb = cv2.cvtColor(source_image.astype('float32'), cv2.COLOR_BGR2RGB)\n",
    "source_tensor = to_tensor(source_image, use_cpu=USE_CPU)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start real time animation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    kp_source = kp_detector(source_tensor)\n",
    "    kp_initial = None\n",
    "    crop_box = (143, 87, 322, 322)\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_processed = preprocess_frame(frame, crop_box)\n",
    "        frame_tensor = to_tensor(frame_processed, use_cpu=USE_CPU)\n",
    "\n",
    "        if kp_initial is None:\n",
    "            kp_initial = kp_detector(frame_tensor)\n",
    "\n",
    "        prediction = generate_frame(\n",
    "            source_tensor, kp_source, frame_tensor, kp_initial,\n",
    "            generator, kp_detector\n",
    "        )\n",
    "\n",
    "        # Join frames\n",
    "        joined = np.concatenate([\n",
    "            source_rgb,\n",
    "            cv2.cvtColor(prediction, cv2.COLOR_RGB2BGR),\n",
    "            frame_processed\n",
    "        ], axis=1)\n",
    "\n",
    "        # Add text-hint\n",
    "        cv2.putText(\n",
    "            joined, \"Press 'Q' to quit\", (10, 245),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "        # Show and write\n",
    "        cv2.imshow(WINDOW_NAME, joined)\n",
    "        out_video.write(np.clip(joined * 255, 0, 255).astype(np.uint8))\n",
    "\n",
    "        if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "out_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Animation by Prepared Video"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "service = VideoAnimationService(\n",
    "    config_path='./data/configs/vox-256.yaml',\n",
    "    checkpoint_path='./data/checkpoints/vox-cpk.pth.tar',\n",
    "    source_image_path='./data/input/monalisa.png',\n",
    "    driving_video_path='./data/output/output.mp4',\n",
    "    result_video_path='./data/output/result.mp4',\n",
    "    relative=False,\n",
    "    adapt_scale=False,\n",
    "    find_best=False,\n",
    "    best_frame=None,\n",
    "    cpu=True,\n",
    ")\n",
    "service.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
